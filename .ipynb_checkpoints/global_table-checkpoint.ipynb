{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import fnmatch\n",
    "from lxml import etree\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import IPython\n",
    "import argparse\n",
    "import re\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums=['I ','V ','X ','C ','L ','I.','V.','X.','C.','L.','1','2','3','4','5','6','7','8','9','0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This software generates a csv with basic statistics on a selected corpus \\nusage: --dir path/to/your/source/dir --csv path/to/your/target/directory/for/csv')\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dir', help= '/your/directory/to/tagged/files/')\n",
    "parser.add_argument('--csv', help= '/your/directory/to/your/csv/file/')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_folder=args.dir\n",
    "files_list=fnmatch.filter(os.listdir(path_to_folder), '*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "argsdir='/home/odysseus/Bureau/ANR/corpus/tagged_rest/'\n",
    "argscsv='/home/odysseus/Bureau/ANR/code/global_array/'\n",
    "files_list=fnmatch.filter(os.listdir(argsdir), '*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1642\n",
      "1642\n",
      "File done : 1858_Segur-comtesse-de_Les-Malheurs-de-Sophie.xml\n",
      "3560\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8b2e5903dfe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_chapter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//div[@type='chapter']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//word[@postag='PUNsent']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_verb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//word[@postag='VERB']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_adverb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//word[starts-with(@postag, 'ADV')]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_header=0\n",
    "with open(argscsv+'rest.csv', 'w') as f:\n",
    "    for file in files_list:\n",
    "        dic_stats=OrderedDict()\n",
    "        tmpFile=file.replace(\"/\",\":\")\n",
    "        full_path=argsdir+tmpFile\n",
    "        if os.path.isfile(full_path):\n",
    "            tree=etree.parse(full_path)\n",
    "            if tree.findall(\".//div[@type='chapter']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='chapter']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='chapter']\")[int(len(tree.findall(\".//div[@type='chapter']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='chapter']\")[len(tree.findall(\".//div[@type='chapter']\"))-1]\n",
    "            elif tree.findall(\".//div[@type='book']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='book']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='book']\")[int(len(tree.findall(\".//div[@type='book']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='book']\")[len(tree.findall(\".//div[@type='book']\"))-1]\n",
    "            elif tree.findall(\".//div[@type='part']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='part']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='part']\")[int(len(tree.findall(\".//div[@type='part']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='part']\")[len(tree.findall(\".//div[@type='part']\"))-1]\n",
    "            \n",
    "            dic_stats['ref']=file\n",
    "            dic_stats['title']=re.sub(u'\\n','',tree.find(\".//title\").text).replace(\"     \",\"\")\n",
    "            dic_stats['author']=tree.find(\".//author\").attrib['name']\n",
    "            dic_stats['date']=tree.find(\".//date\").attrib['when']\n",
    "            #dic_stats['genre']=tree.find(\".//term\").text\n",
    "            dic_stats['canon_degree']=\"empty\"\n",
    "            total_words = tree.findall(\".//word\")\n",
    "            nb_words = len(total_words)\n",
    "            dic_stats['glob_word']= nb_words\n",
    "            first_ten = etree.Element(\"first\")\n",
    "            for word in total_words[0:int(((10*nb_words)/100))]:\n",
    "                first_ten.append(deepcopy(word))\n",
    "            last_ten = etree.Element(\"last\")\n",
    "            for word in total_words[nb_words-int(((10*nb_words)/100)):nb_words]:\n",
    "                last_ten.append(deepcopy(word))\n",
    "            \n",
    "            dic_stats['glob_book']=len(tree.findall(\".//div[@type='book']\"))\n",
    "            dic_stats['glob_part']=len(tree.findall(\".//div[@type='part']\"))\n",
    "            dic_stats['glob_chapter']=len(tree.findall(\".//div[@type='chapter']\"))\n",
    "            dic_stats['glob_paragraph']=len(tree.findall(\".//p\"))\n",
    "            dic_stats['glob_sentence']=len(tree.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['glob_verb']=len(tree.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['glob_adverb']=len(tree.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['glob_adj']=len(tree.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['glob_coord']=len(tree.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['glob_sub']=len(tree.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['glob_il']=len(tree.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['glob_ils']=len(tree.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['glob_elle']=len(tree.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['glob_elles']=len(tree.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['glob_je']=len(tree.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['glob_nous']=len(tree.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['glob_etat']=len(tree.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['glob_voc']=len(set(tree.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['first_word']=len(first_chap.findall(\".//word\"))\n",
    "            dic_stats['first_paragraph']=len(first_chap.findall(\".//p\"))\n",
    "            dic_stats['first_sentence']=len(first_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['first_verb']=len(first_chap.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['first_adverb']=len(first_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['first_adj']=len(first_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['first_coord']=len(first_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['first_sub']=len(first_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['first_il']=len(first_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['first_ils']=len(first_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['first_elle']=len(first_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['first_elles']=len(first_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['first_je']=len(first_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['first_nous']=len(first_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['first_etat']=len(first_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['first_voc']=len(set(first_chap.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['first_ten_word']=len(first_ten.findall(\".//word\"))\n",
    "            dic_stats['first_ten_sentence']=len(first_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['first_ten_verb']=len(first_ten.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['first_ten_adverb']=len(first_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['first_ten_adj']=len(first_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['first_ten_coord']=len(first_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['first_ten_sub']=len(first_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['first_ten_il']=len(first_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['first_ten_ils']=len(first_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['first_ten_elle']=len(first_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['first_ten_elles']=len(first_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['first_ten_je']=len(first_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['first_ten_nous']=len(first_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['first_ten_etat']=len(first_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['first_ten_voc']=len(set(first_ten.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['mid_word']=len(middle_chap.findall(\".//word\"))\n",
    "            dic_stats['mid_paragraph']=len(middle_chap.findall(\".//p\"))\n",
    "            dic_stats['mid_sentence']=len(middle_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['mid_verb']=len(middle_chap.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['mid_adverb']=len(middle_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['mid_adj']=len(middle_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['mid_coord']=len(middle_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['mid_sub']=len(middle_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['mid_il']=len(middle_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['mid_ils']=len(middle_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['mid_elle']=len(middle_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['mid_elles']=len(middle_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['mid_je']=len(middle_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['mid_nous']=len(middle_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['mid_etat']=len(middle_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['mid_voc']=len(set(middle_chap.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['last_word']=len(last_chap.findall(\".//word\"))\n",
    "            dic_stats['last_paragraph']=len(last_chap.findall(\".//p\"))\n",
    "            dic_stats['last_sentence']=len(last_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['last_verb']=len(last_chap.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['last_adverb']=len(last_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['last_adj']=len(last_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['last_coord']=len(last_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['last_sub']=len(last_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['last_il']=len(last_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['last_ils']=len(last_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['last_elle']=len(last_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['last_elles']=len(last_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['last_je']=len(last_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['last_nous']=len(last_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['last_etat']=len(last_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['last_voc']=len(set(last_chap.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['last_ten_word']=len(last_ten.findall(\".//word\"))\n",
    "            dic_stats['last_ten_paragraph']=len(last_ten.findall(\".//p\"))\n",
    "            dic_stats['last_ten_sentence']=len(last_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['last_ten_verb']=len(last_ten.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['last_ten_adverb']=len(last_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['last_ten_adj']=len(last_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['last_ten_coord']=len(last_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['last_ten_sub']=len(last_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['last_ten_il']=len(last_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['last_ten_ils']=len(last_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['last_ten_elle']=len(last_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['last_ten_elles']=len(last_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['last_ten_je']=len(last_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['last_ten_nous']=len(last_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['last_ten_etat']=len(last_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['last_ten_voc']=len(set(last_ten.xpath(\".//word/@lemma\")))\n",
    "            titles_book=0\n",
    "            num_book=0\n",
    "            for element in tree.findall(\".//div[@type='book'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_book+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_book+=1\n",
    "            titles_part=0\n",
    "            num_part=0\n",
    "            for element in tree.findall(\".//div[@type='part'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_part+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_part+=1\n",
    "            titles_chap=0\n",
    "            num_chap=0\n",
    "            for element in tree.findall(\".//div[@type='chapter'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_chap+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_chap+=1\n",
    "            dic_stats['titled_books']=titles_book\n",
    "            dic_stats['titled_parts']=titles_part\n",
    "            dic_stats['titled_chapters']=titles_chap\n",
    "            dic_stats['numbered_books']=num_book\n",
    "            dic_stats['numbered_parts']=num_part\n",
    "            dic_stats['numbered_chapters']=num_chap\n",
    "            headers=list(dic_stats.keys())\n",
    "            writer = csv.DictWriter(f, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "            if (count_header==0):\n",
    "                writer.writeheader()\n",
    "                count_header += 1\n",
    "            writer2 = csv.writer(f)\n",
    "            writer2.writerow(list(dic_stats.values()))\n",
    "        print('File done : '+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
