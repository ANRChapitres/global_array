{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import fnmatch\n",
    "from lxml import etree\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import IPython\n",
    "import argparse\n",
    "import re\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums=['I ','V ','X ','C ','L ','I.','V.','X.','C.','L.','1','2','3','4','5','6','7','8','9','0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This software generates a csv with basic statistics on a selected corpus \\nusage: --dir path/to/your/source/dir --csv path/to/your/target/directory/for/csv')\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dir', help= '/your/directory/to/tagged/files/')\n",
    "parser.add_argument('--csv', help= '/your/directory/to/your/csv/file/')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_folder=args.dir\n",
    "files_list=fnmatch.filter(os.listdir(path_to_folder), '*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "argsdir='/home/odysseus/Bureau/ANR/corpus/tagged_rest/'\n",
    "argscsv='/home/odysseus/Bureau/ANR/code/global_array/'\n",
    "files_list=fnmatch.filter(os.listdir(argsdir), '*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File done : 1858_Segur-comtesse-de_Les-Malheurs-de-Sophie.xml\n",
      "File done : 1850_Dumas-Alexandre_Le-Vicomte-de-Bragelonne.xml\n",
      "File done : 2014_Volodine-Antoine_Terminus-radieux.xml\n",
      "File done : 1909_Boylesve-Rene_La-jeune-fille-bien-elevee.xml\n",
      "File done : 1872_Zola-Emile_La-curee.xml\n",
      "File done : 1861_Erckmann-Chatrian_Confidences-d-un-joueur-de-clarinette.xml\n",
      "File done : 1920_Toulet-Paul-Jean_La-jeune-fille-verte-roman.xml\n",
      "File done : 1961_Troyat-Henri_La-gloire-des-vaincus.xml\n",
      "File done : 1888_Malot-Hector_Conscience.xml\n",
      "File done : 1944_Aragon-Louis_Aurelien.xml\n",
      "File done : 1951_Rebatet-Lucien_Les-Deux-Etendards.xml\n",
      "File done : 1991_Bauchau-Henry_Diotime-et-les-lions.xml\n",
      "File done : 1847_Collin-de-Plancy-Jacques-Albin-Simon-(1794-1881)_Legende-du-Juif-Errant.xml\n",
      "File done : 1861_Rocca-Maria-della-(nee-Embden-Heine-pseud-Camille-Henry-Princesse)_Le-Roman-d-une-femme-laide.xml\n",
      "File done : 1977_Ernaux-Annie_Ce-qu-ils-disent-ou-rien.xml\n",
      "File done : 1843_Doutre-Joseph_Les-fiances-de-1812.xml\n",
      "File done : 1949_Simenon-Georges_Mon-ami-Maigret.xml\n",
      "File done : 1897_Roussel-Raymond_La-doublure.xml\n",
      "File done : 1994_Rolin-Olivier_Port-Soudan.xml\n",
      "File done : 1921_Leroux-Gaston_Cheri-Bibi-et-Cecily.xml\n",
      "File done : 1972_A.D.G._Cradoque-s-band.xml\n",
      "File done : 1880_Karr-Alphonse_Bourdonnements.xml\n",
      "File done : 1847_Sandeau-Jules_Mademoiselle-de-la-Seigli__re-Volume-1.xml\n",
      "File done : 1909_Giraudoux-Jean_Provinciales.xml\n",
      "File done : 1959_Sarraute-Nathalie_Le-Planetarium.xml\n",
      "File done : 1994_Chevillard-Eric_Prehistoire.xml\n",
      "File done : 1845_Merimee-Prosper_Carmen.xml\n",
      "File done : 1931_Saint-Exupery-Antoine-de_Vol-de-nuit.xml\n",
      "File done : 1877_Goncourt-Edmond-et-Jules-de_La-fille-Elisa.xml\n",
      "File done : 1935_Duhamel-Georges_La-nuit-de-la-Saint-Jean.xml\n",
      "File done : 1942_Vercors_Le-silence-de-la-mer.xml\n",
      "File done : 1930_Galopin-Arnould_Le-sergent-Bucaille.xml\n",
      "File done : 1929_Dabit-Eugene_L-Hotel-du-Nord.xml\n",
      "File done : 1865_Erckmann-Chatrian_Histoire-d-un-homme-du-peuple.xml\n",
      "File done : 1907_Segalen-Victor_Les-Immemoriaux.xml\n",
      "File done : 1909_Leblanc-Maurice_L-Aiguille-creuse.xml\n",
      "File done : 1999_Echenoz-Jean_Je-m-en-vais.xml\n",
      "File done : 1962_Simenon-Georges_Maigret-et-les-braves-gens.xml\n",
      "File done : 1863_Fromentin-Eugene_Dominique.xml\n",
      "File done : 1987_Chevillard-Eric_Mourir-m-enrhume.xml\n",
      "File done : 2010_Volodine-Andoine-(pseudonyme--Lutz-Bassmann)_Les-aigles-puent.xml\n",
      "File done : 2001_Rufin-Jean-Christophe_Rouge-Bresil.xml\n",
      "File done : 1967_Perec-Georges_Un-homme-qui-dort.xml\n",
      "File done : 1909_Colette_L-Ingenue-libertine.xml\n",
      "File done : 1886_Loti-Pierre_Pecheur-d-Islande.xml\n",
      "File done : 1899_Adam-Paul_La-Force.xml\n",
      "File done : 1926_Mac-Orlan-Pierre_Les-clients-du-Bon-Chien-Jaune.xml\n",
      "File done : 1967_Simenon-Georges_Le-voleur-de-Maigret.xml\n",
      "File done : 1848_Balzac-Honore-de_Les-Parents-pauvres-La-Cousine-BetteFC.xml\n",
      "File done : 1957_Pagnol-Marcel_Le-Chateau-de-ma-mere.xml\n",
      "File done : 1956_Thomas-Henri_La-nuit-de-Londres.xml\n",
      "File done : 1890_Pont-Jest-Rene-de_Le-Fleuve-des-perles-(L-araignee-Rouge).xml\n",
      "File done : 1887_Verne-Jules_Nord-contre-Sud.xml\n",
      "File done : 2002_Rolin-Olivier_Tigre-en-papier.xml\n",
      "File done : 1881_Verne-Jules-_La-Jangada-huit-cent-lieues-sur-l-Amazone].xml\n",
      "File done : 1954_Cohen-Albert_Le-livre-de-ma-mere.xml\n",
      "File done : 1923_Malot-Hector_Romain-Kalbris.xml\n",
      "File done : 1995_Bergounioux-Pierre_Miette.xml\n",
      "File done : 1947_Antelme-Robert_l-espece-humaine.xml\n",
      "File done : 1955_San-Antonio_Le-fil-a-couper-le-beurre.xml\n",
      "File done : 1912_Loti-Pierre_Un-pelerin-d-Angkor.xml\n",
      "File done : 1919_Bazin-Rene_Les-Nouveaux-Oberle.xml\n",
      "File done : 1891_Huysmans-Joris-Karl_La-bas.xml\n",
      "File done : 1949_San-Antonio_Reglez-lui-son-compte-.xml\n",
      "File done : 1933_Leblanc-Maurice_La-femme-aux-deux-sourires.xml\n",
      "File done : 1892_Loti-Pierre_Fantome-d-Orient.xml\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-897dfcff8507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_il'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//word[@form='il']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_ils'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//word[@form='ils']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_elle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//word[@form='elle']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_elles'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//word[@form='elles']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mdic_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'glob_je'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".//word[@form='je']\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_header=0\n",
    "with open(argscsv+'rest.csv', 'w') as f:\n",
    "    for file in files_list:\n",
    "        dic_stats=OrderedDict()\n",
    "        tmpFile=file.replace(\"/\",\":\")\n",
    "        full_path=argsdir+tmpFile\n",
    "        if os.path.isfile(full_path):\n",
    "            tree=etree.parse(full_path)\n",
    "            if tree.findall(\".//div[@type='chapter']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='chapter']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='chapter']\")[int(len(tree.findall(\".//div[@type='chapter']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='chapter']\")[len(tree.findall(\".//div[@type='chapter']\"))-1]\n",
    "            elif tree.findall(\".//div[@type='book']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='book']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='book']\")[int(len(tree.findall(\".//div[@type='book']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='book']\")[len(tree.findall(\".//div[@type='book']\"))-1]\n",
    "            elif tree.findall(\".//div[@type='part']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='part']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='part']\")[int(len(tree.findall(\".//div[@type='part']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='part']\")[len(tree.findall(\".//div[@type='part']\"))-1]\n",
    "            \n",
    "            dic_stats['ref']=file\n",
    "            dic_stats['title']=re.sub(u'\\n','',tree.find(\".//title\").text).replace(\"     \",\"\")\n",
    "            dic_stats['author']=tree.find(\".//author\").attrib['name']\n",
    "            dic_stats['date']=tree.find(\".//date\").attrib['when']\n",
    "            #dic_stats['genre']=tree.find(\".//term\").text\n",
    "            dic_stats['canon_degree']=\"empty\"\n",
    "            total_words = tree.findall(\".//word\")\n",
    "            nb_words = len(total_words)\n",
    "            dic_stats['glob_word']= nb_words\n",
    "            first_ten = etree.Element(\"first\")\n",
    "            for word in total_words[0:int(((10*nb_words)/100))]:\n",
    "                first_ten.append(deepcopy(word))\n",
    "            last_ten = etree.Element(\"last\")\n",
    "            for word in total_words[nb_words-int(((10*nb_words)/100)):nb_words]:\n",
    "                last_ten.append(deepcopy(word))\n",
    "            \n",
    "            dic_stats['glob_book']=len(tree.findall(\".//div[@type='book']\"))\n",
    "            dic_stats['glob_part']=len(tree.findall(\".//div[@type='part']\"))\n",
    "            dic_stats['glob_chapter']=len(tree.findall(\".//div[@type='chapter']\"))\n",
    "            dic_stats['glob_paragraph']=len(tree.findall(\".//p\"))\n",
    "            dic_stats['glob_sentence']=len(tree.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['glob_verb']=len(tree.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['glob_adverb']=len(tree.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['glob_adj']=len(tree.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['glob_coord']=len(tree.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['glob_sub']=len(tree.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['glob_il']=len(tree.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['glob_ils']=len(tree.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['glob_elle']=len(tree.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['glob_elles']=len(tree.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['glob_je']=len(tree.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['glob_nous']=len(tree.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['glob_etat']=len(tree.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['glob_voc']=len(set(tree.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['first_word']=len(first_chap.findall(\".//word\"))\n",
    "            dic_stats['first_paragraph']=len(first_chap.findall(\".//p\"))\n",
    "            dic_stats['first_sentence']=len(first_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['first_verb']=len(first_chap.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['first_adverb']=len(first_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['first_adj']=len(first_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['first_coord']=len(first_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['first_sub']=len(first_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['first_il']=len(first_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['first_ils']=len(first_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['first_elle']=len(first_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['first_elles']=len(first_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['first_je']=len(first_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['first_nous']=len(first_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['first_etat']=len(first_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['first_voc']=len(set(first_chap.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['first_ten_word']=len(first_ten.findall(\".//word\"))\n",
    "            dic_stats['first_ten_sentence']=len(first_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['first_ten_verb']=len(first_ten.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['first_ten_adverb']=len(first_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['first_ten_adj']=len(first_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['first_ten_coord']=len(first_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['first_ten_sub']=len(first_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['first_ten_il']=len(first_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['first_ten_ils']=len(first_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['first_ten_elle']=len(first_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['first_ten_elles']=len(first_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['first_ten_je']=len(first_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['first_ten_nous']=len(first_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['first_ten_etat']=len(first_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['first_ten_voc']=len(set(first_ten.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['mid_word']=len(middle_chap.findall(\".//word\"))\n",
    "            dic_stats['mid_paragraph']=len(middle_chap.findall(\".//p\"))\n",
    "            dic_stats['mid_sentence']=len(middle_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['mid_verb']=len(middle_chap.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['mid_adverb']=len(middle_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['mid_adj']=len(middle_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['mid_coord']=len(middle_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['mid_sub']=len(middle_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['mid_il']=len(middle_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['mid_ils']=len(middle_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['mid_elle']=len(middle_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['mid_elles']=len(middle_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['mid_je']=len(middle_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['mid_nous']=len(middle_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['mid_etat']=len(middle_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['mid_voc']=len(set(middle_chap.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['last_word']=len(last_chap.findall(\".//word\"))\n",
    "            dic_stats['last_paragraph']=len(last_chap.findall(\".//p\"))\n",
    "            dic_stats['last_sentence']=len(last_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['last_verb']=len(last_chap.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['last_adverb']=len(last_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['last_adj']=len(last_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['last_coord']=len(last_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['last_sub']=len(last_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['last_il']=len(last_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['last_ils']=len(last_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['last_elle']=len(last_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['last_elles']=len(last_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['last_je']=len(last_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['last_nous']=len(last_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['last_etat']=len(last_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['last_voc']=len(set(last_chap.xpath(\".//word/@lemma\")))\n",
    "            dic_stats['last_ten_word']=len(last_ten.findall(\".//word\"))\n",
    "            dic_stats['last_ten_paragraph']=len(last_ten.findall(\".//p\"))\n",
    "            dic_stats['last_ten_sentence']=len(last_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['last_ten_verb']=len(last_ten.findall(\".//word[@postag='VERB']\"))\n",
    "            dic_stats['last_ten_adverb']=len(last_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['last_ten_adj']=len(last_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['last_ten_coord']=len(last_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['last_ten_sub']=len(last_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['last_ten_il']=len(last_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['last_ten_ils']=len(last_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['last_ten_elle']=len(last_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['last_ten_elles']=len(last_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['last_ten_je']=len(last_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['last_ten_nous']=len(last_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['last_ten_etat']=len(last_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['last_ten_voc']=len(set(last_ten.xpath(\".//word/@lemma\")))\n",
    "            titles_book=0\n",
    "            num_book=0\n",
    "            for element in tree.findall(\".//div[@type='book'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_book+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_book+=1\n",
    "            titles_part=0\n",
    "            num_part=0\n",
    "            for element in tree.findall(\".//div[@type='part'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_part+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_part+=1\n",
    "            titles_chap=0\n",
    "            num_chap=0\n",
    "            for element in tree.findall(\".//div[@type='chapter'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_chap+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_chap+=1\n",
    "            dic_stats['titled_books']=titles_book\n",
    "            dic_stats['titled_parts']=titles_part\n",
    "            dic_stats['titled_chapters']=titles_chap\n",
    "            dic_stats['numbered_books']=num_book\n",
    "            dic_stats['numbered_parts']=num_part\n",
    "            dic_stats['numbered_chapters']=num_chap\n",
    "            headers=list(dic_stats.keys())\n",
    "            writer = csv.DictWriter(f, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "            if (count_header==0):\n",
    "                writer.writeheader()\n",
    "                count_header += 1\n",
    "            writer2 = csv.writer(f)\n",
    "            writer2.writerow(list(dic_stats.values()))\n",
    "        print('File done : '+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
