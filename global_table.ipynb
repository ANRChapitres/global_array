{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "import fnmatch\n",
    "from lxml import etree\n",
    "from collections import OrderedDict\n",
    "import csv\n",
    "import IPython\n",
    "import argparse\n",
    "import re\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums=['I ','V ','X ','C ','L ','I.','V.','X.','C.','L.','1','2','3','4','5','6','7','8','9','0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This software generates a csv with basic statistics on a selected corpus \\nusage: --dir path/to/your/source/dir --csv path/to/your/target/directory/for/csv')\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dir', help= '/your/directory/to/tagged/files/')\n",
    "parser.add_argument('--csv', help= '/your/directory/to/your/csv/file/')\n",
    "args = parser.parse_args()\n",
    "if len(sys.argv) == 1:\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argsdir= os.path.join(args.dir, '')\n",
    "argscsv= os.path.join(args.csv, '')\n",
    "files_list=fnmatch.filter(os.listdir(path_to_folder), '*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "argsdir='/home/odysseus/Bureau/ANR/corpus/test_zone/'\n",
    "argscsv='/home/odysseus/Bureau/ANR/code/global_array/'\n",
    "files_list=fnmatch.filter(os.listdir(argsdir), '*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_words_sent(tree):\n",
    "    average = 0\n",
    "    indexes=list()\n",
    "    for sent in tree.findall(\".//word[@postag='PUNsent']\"):\n",
    "        indexes.append(sent.getparent().index(sent))\n",
    "                #print(sent.getparent().index(sent))\n",
    "    words_between=list()\n",
    "    for idx, index in enumerate(indexes):\n",
    "        if idx == 0:\n",
    "            if len(indexes) == 1:\n",
    "                words_between.append(index)\n",
    "            elif len(indexes) > 1:\n",
    "                words_between.append(indexes[idx+1]-index-1)\n",
    "        elif idx < len(indexes)-1 :\n",
    "            if index<indexes[idx+1]:\n",
    "                words_between.append(indexes[idx+1]-index-1)\n",
    "    if len(words_between) > 0:\n",
    "        average = int(sum(words_between)/len(words_between))\n",
    "    else :\n",
    "        print(\"No sentence found in this section\")\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File done : 1857_Flaubert-Gustave_Madame-Bovary.xml\n"
     ]
    }
   ],
   "source": [
    "count_header=0\n",
    "with open(argscsv+'rest.csv', 'w') as f:\n",
    "    for file in files_list:\n",
    "        dic_stats=OrderedDict()\n",
    "        tmpFile=file.replace(\"/\",\":\")\n",
    "        full_path=argsdir+tmpFile\n",
    "        if os.path.isfile(full_path):\n",
    "            tree=etree.parse(full_path)\n",
    "            if tree.findall(\".//div[@type='chapter']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='chapter']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='chapter']\")[int(len(tree.findall(\".//div[@type='chapter']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='chapter']\")[len(tree.findall(\".//div[@type='chapter']\"))-1]\n",
    "            elif tree.findall(\".//div[@type='book']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='book']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='book']\")[int(len(tree.findall(\".//div[@type='book']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='book']\")[len(tree.findall(\".//div[@type='book']\"))-1]\n",
    "            elif tree.findall(\".//div[@type='part']\"):\n",
    "                first_chap = tree.findall(\".//div[@type='part']\")[0]\n",
    "                middle_chap = tree.findall(\".//div[@type='part']\")[int(len(tree.findall(\".//div[@type='part']\"))/2)]\n",
    "                last_chap = tree.findall(\".//div[@type='part']\")[len(tree.findall(\".//div[@type='part']\"))-1]\n",
    "            \n",
    "            dic_stats['ref']=file\n",
    "            dic_stats['title']=re.sub(u'\\n','',tree.find(\".//title\").text).replace(\"     \",\"\")\n",
    "            dic_stats['author']=tree.find(\".//author\").attrib['name']\n",
    "            dic_stats['date']=tree.find(\".//date\").attrib['when']\n",
    "            #dic_stats['genre']=tree.find(\".//term\").text\n",
    "            dic_stats['canon_degree']=\"empty\"\n",
    "            total_words = tree.findall(\".//word\")\n",
    "            nb_words = len(total_words)\n",
    "            dic_stats['glob_word']= nb_words\n",
    "            first_ten = etree.Element(\"first\")\n",
    "            second_ten = etree.Element(\"second\")\n",
    "            third_ten = etree.Element(\"third\")\n",
    "            fourth_ten = etree.Element(\"fourth\")\n",
    "            fifth_ten = etree.Element(\"fifth\")\n",
    "            sixth_ten = etree.Element(\"sixth\")\n",
    "            seventh_ten = etree.Element(\"seventh\")\n",
    "            eigth_ten = etree.Element(\"eigth\")\n",
    "            ninth_ten = etree.Element(\"ninth\")\n",
    "            last_ten = etree.Element(\"tenth\")\n",
    "            \n",
    "            percents=list(chunks(total_words,round(((10*nb_words)/100))))\n",
    "            \n",
    "            if len(percents)>10:\n",
    "                percents[9].extend(percents[10])\n",
    "                percents.pop(10)\n",
    "            \n",
    "            for word in percents[0]:\n",
    "                first_ten.append(deepcopy(word))\n",
    "            for word in percents[1]:\n",
    "                second_ten.append(deepcopy(word))\n",
    "            for word in percents[2]:\n",
    "                third_ten.append(deepcopy(word))\n",
    "            for word in percents[3]:\n",
    "                fourth_ten.append(deepcopy(word))\n",
    "            for word in percents[4]:\n",
    "                fifth_ten.append(deepcopy(word))\n",
    "            for word in percents[5]:\n",
    "                sixth_ten.append(deepcopy(word))\n",
    "            for word in percents[6]:\n",
    "                seventh_ten.append(deepcopy(word))\n",
    "            for word in percents[7]:\n",
    "                eigth_ten.append(deepcopy(word))\n",
    "            for word in percents[8]:\n",
    "                ninth_ten.append(deepcopy(word))\n",
    "            for word in percents[9]:\n",
    "                last_ten.append(deepcopy(word))\n",
    "           \n",
    "            \n",
    "            dic_stats['glob_book']=len(tree.findall(\".//div[@type='book']\"))\n",
    "            dic_stats['glob_part']=len(tree.findall(\".//div[@type='part']\"))\n",
    "            dic_stats['glob_chapter']=len(tree.findall(\".//div[@type='chapter']\"))\n",
    "            dic_stats['glob_paragraph']=len(tree.findall(\".//p\"))\n",
    "            dic_stats['glob_sentence']=len(tree.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['glob_av_word_per_sent']= average_words_sent(tree)\n",
    "            dic_stats['glob_name']=len(set(tree.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['glob_verb']=len(tree.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['glob_adverb']=len(tree.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['glob_adj']=len(tree.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['glob_coord']=len(tree.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['glob_sub']=len(tree.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['glob_il']=len(tree.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['glob_ils']=len(tree.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['glob_elle']=len(tree.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['glob_elles']=len(tree.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['glob_je']=len(tree.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['glob_nous']=len(tree.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['glob_etat']=len(tree.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['glob_voc']=len(set(tree.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['first_word']=len(first_chap.findall(\".//word\"))\n",
    "            dic_stats['first_paragraph']=len(first_chap.findall(\".//p\"))\n",
    "            dic_stats['first_sentence']=len(first_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['first_av_word_per_sent']= average_words_sent(first_chap)\n",
    "            dic_stats['first_name']=len(set(first_chap.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['first_verb']=len(first_chap.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['first_adverb']=len(first_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['first_adj']=len(first_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['first_coord']=len(first_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['first_sub']=len(first_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['first_il']=len(first_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['first_ils']=len(first_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['first_elle']=len(first_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['first_elles']=len(first_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['first_je']=len(first_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['first_nous']=len(first_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['first_etat']=len(first_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['first_voc']=len(set(first_chap.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['1/10_words']=len(first_ten.findall(\".//word\"))\n",
    "            dic_stats['1/10_sentence']=len(first_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['1/10_av_word_per_sent']= average_words_sent(first_ten)\n",
    "            dic_stats['1/10_name']=len(set(first_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['1/10_verb']=len(first_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['1/10_adverb']=len(first_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['1/10_adj']=len(first_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['1/10_coord']=len(first_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['1/10_sub']=len(first_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['1/10_il']=len(first_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['1/10_ils']=len(first_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['1/10_elle']=len(first_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['1/10_elles']=len(first_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['1/10_je']=len(first_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['1/10_nous']=len(first_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['1/10_etat']=len(first_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['1/10_voc']=len(set(first_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['2/10_word']=len(second_ten.findall(\".//word\"))\n",
    "            dic_stats['2/10_sentence']=len(second_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['2/10_av_word_per_sent']= average_words_sent(second_ten)\n",
    "            dic_stats['2/10_name']=len(set(second_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['2/10_verb']=len(second_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['2/10_adverb']=len(second_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['2/10_adj']=len(second_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['2/10_coord']=len(second_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['2/10_sub']=len(second_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['2/10_il']=len(second_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['2/10_ils']=len(second_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['2/10_elle']=len(second_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['2/10_elles']=len(second_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['2/10_je']=len(second_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['2/10_nous']=len(second_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['2/10_etat']=len(second_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['2/10_voc']=len(set(second_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['3/10_word']=len(third_ten.findall(\".//word\"))\n",
    "            dic_stats['3/10_sentence']=len(third_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['3/10_av_word_per_sent']= average_words_sent(third_ten)\n",
    "            dic_stats['3/10_name']=len(set(third_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['3/10_verb']=len(third_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['3/10_adverb']=len(third_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['3/10_adj']=len(third_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['3/10_coord']=len(third_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['3/10_sub']=len(third_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['3/10_il']=len(third_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['3/10_ils']=len(third_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['3/10_elle']=len(third_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['3/10_elles']=len(third_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['3/10_je']=len(third_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['3/10_nous']=len(third_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['3/10_etat']=len(third_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['3/10_voc']=len(set(third_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['4/10_word']=len(fourth_ten.findall(\".//word\"))\n",
    "            dic_stats['4/10_sentence']=len(fourth_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['4/10_av_word_per_sent']= average_words_sent(fourth_ten)\n",
    "            dic_stats['4/10_name']=len(set(fourth_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['4/10_verb']=len(fourth_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['4/10_adverb']=len(fourth_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['4/10_adj']=len(fourth_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['4/10_coord']=len(fourth_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['4/10_sub']=len(fourth_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['4/10_il']=len(fourth_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['4/10_ils']=len(fourth_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['4/10_elle']=len(fourth_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['4/10_elles']=len(fourth_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['4/10_je']=len(fourth_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['4/10_nous']=len(fourth_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['4/10_etat']=len(fourth_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['4/10_voc']=len(set(fourth_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['5/10_word']=len(fifth_ten.findall(\".//word\"))\n",
    "            dic_stats['5/10_sentence']=len(fifth_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['5/10_av_word_per_sent']= average_words_sent(fifth_ten)\n",
    "            dic_stats['5/10_name']=len(set(fifth_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['5/10_verb']=len(fifth_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['5/10_adverb']=len(fifth_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['5/10_adj']=len(fifth_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['5/10_coord']=len(fifth_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['5/10_sub']=len(fifth_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['5/10_il']=len(fifth_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['5/10_ils']=len(fifth_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['5/10_elle']=len(fifth_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['5/10_elles']=len(fifth_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['5/10_je']=len(fifth_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['5/10_nous']=len(fifth_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['5/10_etat']=len(fifth_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['5/10_voc']=len(set(fifth_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['6/10_word']=len(sixth_ten.findall(\".//word\"))\n",
    "            dic_stats['6/10_sentence']=len(sixth_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['6/10_av_word_per_sent']= average_words_sent(sixth_ten)\n",
    "            dic_stats['6/10_name']=len(set(sixth_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['6/10_verb']=len(sixth_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['6/10_adverb']=len(sixth_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['6/10_adj']=len(sixth_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['6/10_coord']=len(sixth_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['6/10_sub']=len(sixth_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['6/10_il']=len(sixth_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['6/10_ils']=len(sixth_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['6/10_elle']=len(sixth_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['6/10_elles']=len(sixth_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['6/10_je']=len(sixth_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['6/10_nous']=len(sixth_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['6/10_etat']=len(sixth_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['6/10_voc']=len(set(sixth_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['7/10_word']=len(seventh_ten.findall(\".//word\"))\n",
    "            dic_stats['7/10_sentence']=len(seventh_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['7/10_av_word_per_sent']= average_words_sent(seventh_ten)\n",
    "            dic_stats['7/10_name']=len(set(seventh_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['7/10_verb']=len(seventh_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['7/10_adverb']=len(seventh_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['7/10_adj']=len(seventh_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['7/10_coord']=len(seventh_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['7/10_sub']=len(seventh_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['7/10_il']=len(seventh_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['7/10_ils']=len(seventh_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['7/10_elle']=len(seventh_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['7/10_elles']=len(seventh_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['7/10_je']=len(seventh_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['7/10_nous']=len(seventh_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['7/10_etat']=len(seventh_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['7/10_voc']=len(set(seventh_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['8/10_word']=len(eigth_ten.findall(\".//word\"))\n",
    "            dic_stats['8/10_sentence']=len(eigth_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['8/10_av_word_per_sent']= average_words_sent(eigth_ten)\n",
    "            dic_stats['8/10_name']=len(set(eigth_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['8/10_verb']=len(eigth_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['8/10_adverb']=len(eigth_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['8/10_adj']=len(eigth_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['8/10_coord']=len(eigth_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['8/10_sub']=len(eigth_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['8/10_il']=len(eigth_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['8/10_ils']=len(eigth_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['8/10_elle']=len(eigth_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['8/10_elles']=len(eigth_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['8/10_je']=len(eigth_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['8/10_nous']=len(eigth_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['8/10_etat']=len(eigth_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['8/10_voc']=len(set(eigth_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['9/10_word']=len(ninth_ten.findall(\".//word\"))\n",
    "            dic_stats['9/10_sentence']=len(ninth_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['9/10_av_word_per_sent']= average_words_sent(ninth_ten)\n",
    "            dic_stats['9/10_name']=len(set(ninth_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['9/10_verb']=len(ninth_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['9/10_adverb']=len(ninth_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['9/10_adj']=len(ninth_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['9/10_coord']=len(ninth_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['9/10_sub']=len(ninth_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['9/10_il']=len(ninth_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['9/10_ils']=len(ninth_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['9/10_elle']=len(ninth_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['9/10_elles']=len(ninth_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['9/10_je']=len(ninth_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['9/10_nous']=len(ninth_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['9/10_etat']=len(ninth_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['9/10_voc']=len(set(ninth_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['10/10_word']=len(last_ten.findall(\".//word\"))\n",
    "            dic_stats['10/10_sentence']=len(last_ten.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['10/10_av_word_per_sent']= average_words_sent(last_ten)\n",
    "            dic_stats['10/10_name']=len(set(last_ten.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['10/10_verb']=len(last_ten.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['10/10_adverb']=len(last_ten.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['10/10_adj']=len(last_ten.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['10/10_coord']=len(last_ten.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['10/10_sub']=len(last_ten.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['10/10_il']=len(last_ten.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['10/10_ils']=len(last_ten.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['10/10_elle']=len(last_ten.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['10/10_elles']=len(last_ten.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['10/10_je']=len(last_ten.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['10/10_nous']=len(last_ten.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['10/10_etat']=len(last_ten.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['10/10_voc']=len(set(last_ten.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['mid_word']=len(middle_chap.findall(\".//word\"))\n",
    "            dic_stats['mid_paragraph']=len(middle_chap.findall(\".//p\"))\n",
    "            dic_stats['mid_sentence']=len(middle_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['mid_av_word_per_sent']= average_words_sent(middle_chap)\n",
    "            dic_stats['mid_name']=len(set(middle_chap.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['mid_verb']=len(middle_chap.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['mid_adverb']=len(middle_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['mid_adj']=len(middle_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['mid_coord']=len(middle_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['mid_sub']=len(middle_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['mid_il']=len(middle_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['mid_ils']=len(middle_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['mid_elle']=len(middle_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['mid_elles']=len(middle_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['mid_je']=len(middle_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['mid_nous']=len(middle_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['mid_etat']=len(middle_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['mid_voc']=len(set(middle_chap.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            dic_stats['last_word']=len(last_chap.findall(\".//word\"))\n",
    "            dic_stats['last_paragraph']=len(last_chap.findall(\".//p\"))\n",
    "            dic_stats['last_sentence']=len(last_chap.findall(\".//word[@postag='PUNsent']\"))\n",
    "            dic_stats['last_av_word_per_sent']= average_words_sent(last_chap)\n",
    "            dic_stats['last_name']=len(set(last_chap.xpath(\".//word[starts-with(@postag, 'NAME')]/@lemma\")))\n",
    "            dic_stats['last_verb']=len(last_chap.xpath(\".//word[starts-with(@postag,'VERB')]\"))\n",
    "            dic_stats['last_adverb']=len(last_chap.xpath(\".//word[starts-with(@postag, 'ADV')]\"))\n",
    "            dic_stats['last_adj']=len(last_chap.xpath(\".//word[starts-with(@postag, 'ADJ')]\"))\n",
    "            dic_stats['last_coord']=len(last_chap.findall(\".//word[@postag='CONJcoord']\"))\n",
    "            dic_stats['last_sub']=len(last_chap.findall(\".//word[@postag='CONJsubord']\"))\n",
    "            dic_stats['last_il']=len(last_chap.findall(\".//word[@form='il']\"))\n",
    "            dic_stats['last_ils']=len(last_chap.findall(\".//word[@form='ils']\"))\n",
    "            dic_stats['last_elle']=len(last_chap.findall(\".//word[@form='elle']\"))\n",
    "            dic_stats['last_elles']=len(last_chap.findall(\".//word[@form='elles']\"))\n",
    "            dic_stats['last_je']=len(last_chap.findall(\".//word[@form='je']\"))\n",
    "            dic_stats['last_nous']=len(last_chap.findall(\".//word[@form='nous']\"))\n",
    "            dic_stats['last_etat']=len(last_chap.xpath(\".//word[@lemma='être' or @lemma='sembler' or @lemma='devenir' or @lemma='demeurer' or @lemma='rester' ]\"))\n",
    "            dic_stats['last_voc']=len(set(last_chap.xpath(\".//word/@lemma\")))\n",
    "            \n",
    "            titles_book=0\n",
    "            num_book=0\n",
    "            for element in tree.findall(\".//div[@type='book'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_book+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_book+=1\n",
    "                elif re.match(r'\\s*\\b[IVXCL]+\\b',element.attrib[\"title\"]):\n",
    "                    num_book+=1\n",
    "            titles_part=0\n",
    "            num_part=0\n",
    "            for element in tree.findall(\".//div[@type='part'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_part+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_part+=1\n",
    "                elif re.match(r'\\s*\\b[IVXCL]+\\b',element.attrib[\"title\"]):\n",
    "                    num_part+=1\n",
    "            titles_chap=0\n",
    "            num_chap=0\n",
    "            for element in tree.findall(\".//div[@type='chapter'][@title]\"):\n",
    "                if len(element.attrib[\"title\"])>3:\n",
    "                    titles_chap+=1\n",
    "                if any(num in element.attrib[\"title\"] for num in nums):\n",
    "                    num_chap+=1\n",
    "                elif re.match(r'\\s*\\b[IVXCL]+\\b',element.attrib[\"title\"]):\n",
    "                    num_chap+=1\n",
    "            dic_stats['titled_books']=titles_book\n",
    "            dic_stats['titled_parts']=titles_part\n",
    "            dic_stats['titled_chapters']=titles_chap\n",
    "            dic_stats['numbered_books']=num_book\n",
    "            dic_stats['numbered_parts']=num_part\n",
    "            dic_stats['numbered_chapters']=num_chap\n",
    "            headers=list(dic_stats.keys())\n",
    "            writer = csv.DictWriter(f, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "            if (count_header==0):\n",
    "                writer.writeheader()\n",
    "                count_header += 1\n",
    "            writer2 = csv.writer(f)\n",
    "            writer2.writerow(list(dic_stats.values()))\n",
    "        print('File done : '+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
